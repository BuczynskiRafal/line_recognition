{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "np.set_printoptions(precision=6, suppress=True, threshold=10000, linewidth=np.inf)\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.dirname(os.getcwd())\n",
    "dataset = os.path.join('data', 'dataset')\n",
    "data_dir = os.path.join('data', 'images')\n",
    "\n",
    "if not os.path.exists(os.path.join(BASE_DIR, data_dir)):\n",
    "    os.makedirs(os.path.join(BASE_DIR, data_dir))\n",
    "\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "test_dir = os.path.join(data_dir, 'test')\n",
    "\n",
    "for directory in (train_dir, valid_dir, test_dir):\n",
    "    if not os.path.exists(os.path.join(BASE_DIR, directory)):\n",
    "        os.makedirs(os.path.join(BASE_DIR, directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9996\n"
     ]
    }
   ],
   "source": [
    "image_fnames = os.listdir(os.path.join(BASE_DIR, 'data/dataset'))\n",
    "image_fnames = [fname for fname in image_fnames if fname.split('.')[1].lower() in ['jpg', 'png', 'jpeg']]\n",
    "print(len(image_fnames))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Split into train, valid, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = len(image_fnames)\n",
    "\n",
    "train_size = int(np.floor(0.7 * size))\n",
    "valid_size = int(np.floor(0.2 * size))\n",
    "test_size = size - train_size - valid_size\n",
    "\n",
    "train_idx = train_size\n",
    "valid_idx = train_size + valid_size\n",
    "test_idx = train_size + valid_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, fname in enumerate(image_fnames):\n",
    "    if i <= train_idx:\n",
    "        src = os.path.join(BASE_DIR, 'data', 'dataset', fname)\n",
    "        dst = os.path.join(BASE_DIR, train_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif train_idx < i <= valid_idx:\n",
    "        src = os.path.join(BASE_DIR, 'data', 'dataset', fname)\n",
    "        dst = os.path.join(BASE_DIR, valid_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n",
    "    elif valid_idx < i < test_idx:\n",
    "        src = os.path.join(BASE_DIR, 'data', 'dataset', fname)\n",
    "        dst = os.path.join(BASE_DIR, test_dir, fname)\n",
    "        shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set 6998\n",
      "validation set 1999\n",
      "test set 999\n"
     ]
    }
   ],
   "source": [
    "print('train set', len(os.listdir(os.path.join(BASE_DIR, train_dir))))\n",
    "print('validation set', len(os.listdir(os.path.join(BASE_DIR, valid_dir))))\n",
    "print('test set', len(os.listdir(os.path.join(BASE_DIR, test_dir))))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Load images and coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(directory):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(directory):\n",
    "        image = Image.open(os.path.join(directory, filename))\n",
    "        image_array = np.array(image) / 255.0\n",
    "        images.append(image_array)\n",
    "        coordinates = filename.split('.')[0].split('_')\n",
    "        x1, y1, x2, y2 = __builtins__.map(int, coordinates)\n",
    "        label = [x1, y1, x2, y2]\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def coord_map(coords):\n",
    "    heat_maps = []\n",
    "    for coord in coords:\n",
    "        heat_map = np.zeros((64, 64, 1))\n",
    "        heat_map[coord[1], coord[0], 0] = 1\n",
    "        heat_map[coord[3], coord[2], 0] = 1\n",
    "        heat_maps.append(heat_map)\n",
    "    heat_maps = np.array(heat_maps)\n",
    "    return heat_maps\n",
    "\n",
    "train_images, train_labels = load_images(os.path.join(BASE_DIR, train_dir))\n",
    "valid_images, valid_labels = load_images(os.path.join(BASE_DIR, valid_dir))\n",
    "test_images, test_labels = load_images(os.path.join(BASE_DIR, test_dir))\n",
    "\n",
    "train_coords_maps = coord_map(train_labels)\n",
    "valid_coords_maps = coord_map(valid_labels)\n",
    "test_coords_maps = coord_map(test_labels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model():\n",
    "    inputs = Input((64, 64, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "\n",
    "    up1 = UpSampling2D(size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv4)\n",
    "    conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "\n",
    "    output = Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[output])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', AUC()])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "55/55 [==============================] - 91s 2s/step - loss: 0.0502 - accuracy: 0.9971 - auc_2: 0.4973 - val_loss: 0.0072 - val_accuracy: 0.9995 - val_auc_2: 0.4904\n",
      "Epoch 2/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 0.0051 - accuracy: 0.9995 - auc_2: 0.4996 - val_loss: 0.0037 - val_accuracy: 0.9995 - val_auc_2: 0.5013\n",
      "Epoch 3/1000\n",
      "55/55 [==============================] - 87s 2s/step - loss: 0.0034 - accuracy: 0.9995 - auc_2: 0.5606 - val_loss: 0.0031 - val_accuracy: 0.9995 - val_auc_2: 0.7240\n",
      "Epoch 4/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 0.0024 - accuracy: 0.9995 - auc_2: 0.9376 - val_loss: 0.0022 - val_accuracy: 0.9995 - val_auc_2: 0.9954\n",
      "Epoch 5/1000\n",
      "55/55 [==============================] - 85s 2s/step - loss: 0.0017 - accuracy: 0.9995 - auc_2: 0.9972 - val_loss: 0.0015 - val_accuracy: 0.9995 - val_auc_2: 0.9969\n",
      "Epoch 6/1000\n",
      "55/55 [==============================] - 86s 2s/step - loss: 0.0014 - accuracy: 0.9995 - auc_2: 0.9978 - val_loss: 0.0014 - val_accuracy: 0.9995 - val_auc_2: 0.9974\n",
      "Epoch 7/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 0.0013 - accuracy: 0.9995 - auc_2: 0.9979 - val_loss: 0.0012 - val_accuracy: 0.9995 - val_auc_2: 0.9975\n",
      "Epoch 8/1000\n",
      "55/55 [==============================] - 89s 2s/step - loss: 0.0011 - accuracy: 0.9995 - auc_2: 0.9980 - val_loss: 0.0011 - val_accuracy: 0.9995 - val_auc_2: 0.9974\n",
      "Epoch 9/1000\n",
      "55/55 [==============================] - 85s 2s/step - loss: 0.0010 - accuracy: 0.9995 - auc_2: 0.9983 - val_loss: 0.0011 - val_accuracy: 0.9995 - val_auc_2: 0.9981\n",
      "Epoch 10/1000\n",
      "55/55 [==============================] - 87s 2s/step - loss: 9.1075e-04 - accuracy: 0.9995 - auc_2: 0.9984 - val_loss: 9.1832e-04 - val_accuracy: 0.9997 - val_auc_2: 0.9980\n",
      "Epoch 11/1000\n",
      "55/55 [==============================] - 91s 2s/step - loss: 7.7258e-04 - accuracy: 0.9997 - auc_2: 0.9985 - val_loss: 7.4779e-04 - val_accuracy: 0.9997 - val_auc_2: 0.9963\n",
      "Epoch 12/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 6.0764e-04 - accuracy: 0.9998 - auc_2: 0.9987 - val_loss: 5.9550e-04 - val_accuracy: 0.9998 - val_auc_2: 0.9963\n",
      "Epoch 13/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 5.6569e-04 - accuracy: 0.9998 - auc_2: 0.9987 - val_loss: 5.4517e-04 - val_accuracy: 0.9998 - val_auc_2: 0.9981\n",
      "Epoch 14/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 3.8480e-04 - accuracy: 0.9999 - auc_2: 0.9989 - val_loss: 4.0192e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9956\n",
      "Epoch 15/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 2.9483e-04 - accuracy: 0.9999 - auc_2: 0.9990 - val_loss: 3.2960e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9966\n",
      "Epoch 16/1000\n",
      "55/55 [==============================] - 85s 2s/step - loss: 2.1814e-04 - accuracy: 0.9999 - auc_2: 0.9992 - val_loss: 2.3692e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9981\n",
      "Epoch 17/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 1.8167e-04 - accuracy: 0.9999 - auc_2: 0.9992 - val_loss: 2.0823e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9972\n",
      "Epoch 18/1000\n",
      "55/55 [==============================] - 89s 2s/step - loss: 1.4899e-04 - accuracy: 1.0000 - auc_2: 0.9993 - val_loss: 1.8840e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9972\n",
      "Epoch 19/1000\n",
      "55/55 [==============================] - 84s 2s/step - loss: 1.2849e-04 - accuracy: 1.0000 - auc_2: 0.9995 - val_loss: 1.4949e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9980\n",
      "Epoch 20/1000\n",
      "55/55 [==============================] - 85s 2s/step - loss: 1.1810e-04 - accuracy: 1.0000 - auc_2: 0.9996 - val_loss: 1.3422e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9984\n",
      "Epoch 21/1000\n",
      "55/55 [==============================] - 87s 2s/step - loss: 9.8918e-05 - accuracy: 1.0000 - auc_2: 0.9996 - val_loss: 1.2843e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9994\n",
      "Epoch 22/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 9.0320e-05 - accuracy: 1.0000 - auc_2: 0.9997 - val_loss: 1.0991e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9994\n",
      "Epoch 23/1000\n",
      "55/55 [==============================] - 93s 2s/step - loss: 8.0867e-05 - accuracy: 1.0000 - auc_2: 0.9997 - val_loss: 1.0210e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9984\n",
      "Epoch 24/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 7.6829e-05 - accuracy: 1.0000 - auc_2: 0.9997 - val_loss: 1.0297e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9976\n",
      "Epoch 25/1000\n",
      "55/55 [==============================] - 89s 2s/step - loss: 6.6865e-05 - accuracy: 1.0000 - auc_2: 0.9997 - val_loss: 9.5414e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9977\n",
      "Epoch 26/1000\n",
      "55/55 [==============================] - 89s 2s/step - loss: 6.2088e-05 - accuracy: 1.0000 - auc_2: 0.9998 - val_loss: 8.4592e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9987\n",
      "Epoch 27/1000\n",
      "55/55 [==============================] - 85s 2s/step - loss: 5.7348e-05 - accuracy: 1.0000 - auc_2: 0.9999 - val_loss: 1.1869e-04 - val_accuracy: 1.0000 - val_auc_2: 0.9975\n",
      "Epoch 28/1000\n",
      "55/55 [==============================] - 83s 2s/step - loss: 5.6147e-05 - accuracy: 1.0000 - auc_2: 0.9999 - val_loss: 6.6276e-05 - val_accuracy: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 29/1000\n",
      "55/55 [==============================] - 86s 2s/step - loss: 4.7543e-05 - accuracy: 1.0000 - auc_2: 0.9999 - val_loss: 7.0122e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9986\n",
      "Epoch 30/1000\n",
      "55/55 [==============================] - 87s 2s/step - loss: 4.2149e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 6.1738e-05 - val_accuracy: 1.0000 - val_auc_2: 1.0000\n",
      "Epoch 31/1000\n",
      "55/55 [==============================] - 96s 2s/step - loss: 4.1135e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 6.2174e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9986\n",
      "Epoch 32/1000\n",
      "55/55 [==============================] - 89s 2s/step - loss: 3.4450e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 5.1379e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9999\n",
      "Epoch 33/1000\n",
      "55/55 [==============================] - 88s 2s/step - loss: 2.9341e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 4.7387e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9990\n",
      "Epoch 34/1000\n",
      "55/55 [==============================] - 92s 2s/step - loss: 2.7645e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 6.8441e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9979\n",
      "Epoch 35/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 2.6781e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 4.6517e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9991\n",
      "Epoch 36/1000\n",
      "55/55 [==============================] - 92s 2s/step - loss: 2.1671e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 4.1288e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9997\n",
      "Epoch 37/1000\n",
      "55/55 [==============================] - 90s 2s/step - loss: 1.8762e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 5.0532e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9982\n",
      "Epoch 38/1000\n",
      "55/55 [==============================] - 92s 2s/step - loss: 1.8050e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 6.7123e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9977\n",
      "Epoch 39/1000\n",
      "55/55 [==============================] - 92s 2s/step - loss: 2.3346e-05 - accuracy: 1.0000 - auc_2: 1.0000 - val_loss: 4.8379e-05 - val_accuracy: 1.0000 - val_auc_2: 0.9997\n",
      "Epoch 40/1000\n",
      "55/55 [==============================] - 93s 2s/step - loss: 0.0018 - accuracy: 0.9996 - auc_2: 0.9653 - val_loss: 7.2505e-04 - val_accuracy: 0.9997 - val_auc_2: 0.9992\n",
      "Epoch 41/1000\n",
      "55/55 [==============================] - 93s 2s/step - loss: 4.2510e-04 - accuracy: 0.9998 - auc_2: 0.9993 - val_loss: 2.6714e-04 - val_accuracy: 0.9999 - val_auc_2: 0.9999\n",
      "Epoch 41: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28665820190>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_coords_maps, validation_data=(valid_images, valid_coords_maps), epochs=1000, batch_size=128, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Dell\\Documents\\Git\\line_recognition\\model\\saved\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\Dell\\Documents\\Git\\line_recognition\\model\\saved\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(BASE_DIR, 'model', 'saved'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = load_model(os.path.join(BASE_DIR, 'model', 'saved'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Predict heatmaps on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 3s 97ms/step\n"
     ]
    }
   ],
   "source": [
    "predicted_maps = model.predict(test_images)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Predict coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n",
      "Warning: only one cluster identified in the heatmap. Duplicating coordinates.\n"
     ]
    }
   ],
   "source": [
    "def predict_coords(predicted_maps):\n",
    "    predicted_coords = []\n",
    "    for map_argmax in predicted_maps:\n",
    "        thresh = threshold_otsu(map_argmax)\n",
    "        binary_map = map_argmax > thresh\n",
    "        labels = measure.label(binary_map)\n",
    "        centroids = [np.round(prop.centroid).astype(int) for prop in measure.regionprops(labels)]\n",
    "\n",
    "        if len(centroids) < 1:\n",
    "            print(\"Warning: no clusters identified in the heatmap. Adding dummy coordinates.\")\n",
    "            centroids = [np.array([0, 0]), np.array([0, 0])]\n",
    "        elif len(centroids) == 1:\n",
    "            print(\"Warning: only one cluster identified in the heatmap. Duplicating coordinates.\")\n",
    "            centroids = [centroids[0], centroids[0]]\n",
    "        elif len(centroids) > 2:\n",
    "            areas = [prop.area for prop in measure.regionprops(labels)]\n",
    "            centroids = [centroids[i] for i in np.argsort(areas)[-2:]]\n",
    "\n",
    "        start_y = centroids[0][0]\n",
    "        start_x = centroids[0][1]\n",
    "        end_y = centroids[1][0]\n",
    "        end_x = centroids[1][1]\n",
    "\n",
    "        predicted_coords.append(np.array([start_x, start_y, end_x, end_y]))\n",
    "    return predicted_coords\n",
    "\n",
    "pred_coords = predict_coords(predicted_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n",
      "999\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_coords))\n",
    "print(len(test_labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Sort coordinates by x descending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_by_x(coords):\n",
    "    if coords[0] > coords[2]:\n",
    "        coords = np.array([coords[2], coords[3], coords[0], coords[1]])\n",
    "    return coords\n",
    "\n",
    "sorted_pred_coords = [sort_by_x(coords) for coords in pred_coords]\n",
    "sorted_test_coords = [sort_by_x(coords) for coords in test_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(pred_coords, test_labels):\n",
    "    x_start_pred = [coord[0] for coord in pred_coords]\n",
    "    y_start_pred = [coord[1] for coord in pred_coords]\n",
    "    x_end_pred = [coord[2] for coord in pred_coords]\n",
    "    y_end_pred = [coord[3] for coord in pred_coords]\n",
    "    \n",
    "    x_start_test = [coord[0] for coord in test_labels]\n",
    "    y_start_test = [coord[1] for coord in test_labels]\n",
    "    x_end_test = [coord[2] for coord in test_labels]\n",
    "    y_end_test = [coord[3] for coord in test_labels]\n",
    "    \n",
    "    data = {'x_start_test': x_start_test, 'x_start_pred': x_start_pred, 'y_start_test': y_start_test, 'y_start_pred': y_start_pred, \n",
    "            'x_end_test': x_end_test, 'x_end_pred': x_end_pred, 'y_end_test': y_end_test, 'y_end_pred': y_end_pred}\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n",
    "df = create_dataframe(sorted_pred_coords, sorted_test_coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_start_test</th>\n",
       "      <th>x_start_pred</th>\n",
       "      <th>y_start_test</th>\n",
       "      <th>y_start_pred</th>\n",
       "      <th>x_end_test</th>\n",
       "      <th>x_end_pred</th>\n",
       "      <th>y_end_test</th>\n",
       "      <th>y_end_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>61</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_start_test  x_start_pred  y_start_test  y_start_pred  x_end_test   \n",
       "0            22            22            33            33          61  \\\n",
       "1            26            26            14            14          61   \n",
       "2            58            58            19            19          61   \n",
       "3            58            58            62            62          61   \n",
       "4            23            23            29            29          61   \n",
       "\n",
       "   x_end_pred  y_end_test  y_end_pred  \n",
       "0          61          55          55  \n",
       "1          61          55          55  \n",
       "2          62          55          55  \n",
       "3          62          55          55  \n",
       "4          61          56          56  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 9.63\n",
      "MSE: 20.31\n",
      "R2: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def compute_mae(predicted_coords, true_coords):\n",
    "    mae_values = []\n",
    "    for pred, true in zip(predicted_coords, true_coords):\n",
    "        mae_values.append(mean_absolute_error(true, pred))\n",
    "    return np.mean(mae_values)\n",
    "\n",
    "mae = compute_mae(sorted_pred_coords, test_labels)\n",
    "mse = mean_squared_error(sorted_test_coords, sorted_pred_coords)\n",
    "r2 = r2_score(sorted_test_coords, sorted_pred_coords)\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"R2: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
